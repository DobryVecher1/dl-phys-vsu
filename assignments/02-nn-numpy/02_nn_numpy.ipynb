{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiKhgsuaumjZP3YxV+a3Ui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DobryVecher1/dl-phys-vsu/blob/main/assignments/02-nn-numpy/02_nn_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Полносвязная (искусственная) нейронная сеть\n",
        "\n",
        "В этом задании вам предстоит реализовать полносвязную двухслойную нейронную сеть с помощью библиотеки Numpy и применить её для классификации.\n",
        "\n",
        "Архитектура сети будет выглядеть следующим образом:\n",
        "\n",
        "Входные данные $→$ Линейный слой $→$ Функция активации $→$ Линейный слой $→$ Softmax $→$ Loss"
      ],
      "metadata": {
        "id": "zh-9yK1FDOfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Датасет\n",
        "\n",
        "Для задачи будем использовать датасет CIFAR-10 [[ссылка](https://www.cs.toronto.edu/~kriz/cifar.html)]. Загрузим датасет, приведем значения пикселей к интервалу $[0, 1]$, а также осуществим one-hot кодирование целевого вектора.\n",
        "\n",
        "Отобразите несколько изображений и соответствующие им классы."
      ],
      "metadata": {
        "id": "LdFN6FnnGYv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "# Загрузка датасета\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = (x_train/255.0).astype('float32')\n",
        "x_val = (x_val/255.0).astype('float32')\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "IA4qY4VWFuVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Реализация слоев нейронной сети\n",
        "В этом пункте необходимо реализовать forward pass и backward pass для используемых слоев. Функции должны возвращать либо результат действия слоя на входные данные, либо, если `get_grad=True`, градиент(ы).\n",
        "\n",
        "1. **Линейный слой**\n",
        "$$ f(x, W, b) = xW + b $$\n"
      ],
      "metadata": {
        "id": "AKzxBmB4JGHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x, W, b, get_grad=False):\n",
        "    # YOUR CODE HERE\n",
        "    pass"
      ],
      "metadata": {
        "id": "IRiwJ6aHMNHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **ReLU**\n",
        "\n",
        "$$ ReLU(x) = max(x, 0)$$\n",
        "В качестве функции активации будем использовать ReLU; напишите функцию, реализующую его работу."
      ],
      "metadata": {
        "id": "oOjcCXKGMTcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x, get_grad=False):\n",
        "    # YOUR CODE HERE\n",
        "    pass"
      ],
      "metadata": {
        "id": "wALEckf0VCZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Softmax + Cross-entropy loss**\n",
        "\n",
        "$$s_i(x) = \\frac{e^{x_i}}{\\sum\\limits_{j}^K e^{x_j}} $$\n",
        "$$CE(y, \\hat{y}) = - \\frac{1}{N}\\sum\\limits_i^N \\sum\\limits_j^K y_j \\ln\\hat{y_j}$$\n",
        "где $K-$количество классов, $N-$ количество объектов.\n",
        "\n",
        "Если мы используем Softmax вместе с функцией потерь в виде кросс-энтропии, то удобно объединить их вместе в один слой из-за удобства получаемых выражений. Напишите выражения для функции потерь и для градиента (можно без полного вывода) и реализуйте функцию аналогичную прошлому пункту."
      ],
      "metadata": {
        "id": "jNfpId2GNAi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_ce(y_true, x, get_grad=False):\n",
        "    # YOUR CODE HERE\n",
        "    pass"
      ],
      "metadata": {
        "id": "kEmJmdVJVCxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Обучение\n",
        "До начала обучения необходимо сделать еще несколько шагов:\n",
        "\n",
        "- **Инициализация весов**. Начальные значения матриц весов могут сильно влиять на ход обучения. Инициализируйте матрицы $W$ и $b$ случайными числами из нормального распределения.\n",
        "- Выбор **темпа обучения (learning rate)**. Гиперпараметр, отвечающий за размер шага в алгоритме градиентного спуска.\n",
        "- Выбор **количества нейронов в скрытом слое**\n",
        "- **Размер батча**. В глубоком обучении через нейронную сеть редко пропускают сразу весь датасет. Вместо этого входные данные делят на части, которые называются **батчи (batch)**, и пропускают по очереди через сеть, обновляя веса после каждой итерации. Когда все батчи из датасета были использованы для forward и backward проходов, заканчивается **эпоха обучения**.\n",
        "\n",
        "    Такой подход позволяет избежать проблем с памятью (датасет может не помещаться в память целиком), а также улучшить сходимость (обновляем веса после каждого батча, а не только один раз после прохода всего датасета).\n",
        "\n",
        "    Выберите размер батча и разбейте датасет на части."
      ],
      "metadata": {
        "id": "74AJyGhWPhbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCH =\n",
        "BATCH_SIZE_TRAIN =\n",
        "BATCH_SIZE_VAL =\n",
        "\n",
        "INPUT_SIZE = 32 * 32 * 3 # размер картинки\n",
        "HIDDEN_SIZE =\n",
        "OUTPUT_SIZE = 10 # 10 классов\n",
        "LR =\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "T16OvlFQM-Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте процесс обучения сети с заданными параметрами. В конце каждой эпохи выводите значения тренировочного и валидационного **лосса**, а также метрики\n",
        "**Accuracy**. В конце обучения постройте зависимости лоссов и метрик от номера эпохи.\n",
        "\n",
        "Вам необходимо достичь значения Accuracy на валидационном датасете в 50% или более."
      ],
      "metadata": {
        "id": "Lg6ziUspV-Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "IumLMGGDWM8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Перед отправкой сохраните ноутбук с именем в следующем формате: 02_Фамилия.ipynb**"
      ],
      "metadata": {
        "id": "pDjcILHW9_RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8Q6N2Is-BpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}