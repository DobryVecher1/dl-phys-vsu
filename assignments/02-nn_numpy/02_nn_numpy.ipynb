{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOegLaIUsvM5yS7OImeO69+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DobryVecher1/dl-phys-vsu/blob/main/assignments/02-nn_numpy/02_nn_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Полносвязная (искусственная) нейронная сеть\n",
        "\n",
        "В этом задании вам предстоит реализовать полносвязную двухслойную нейронную сеть с помощью библиотеки Numpy и применить её для задачи распознавания цифр.\n",
        "\n",
        "Архитектура сети будет выглядеть следующим образом:\n",
        "\n",
        "Входные данные $→$ Линейный слой $→$ Функция активации $→$ Линейный слой $→$ Softmax $→$ Loss"
      ],
      "metadata": {
        "id": "zh-9yK1FDOfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Датасет\n",
        "\n",
        "Для задачи будем использовать датасет MNIST, который содержит изображения с цифрами. С помощью scikit-learn загрузим датасет, приведем значения пикселей к интервалу $[0, 1]$, а также осуществим one-hot кодирование целевого вектора.\n",
        "\n",
        "Воспользуйтесь библиотекой scikit-learn, чтобы разделить датасет на тренировочную и валидационную части. Отобразите несколько изображений и соответствующие им классы."
      ],
      "metadata": {
        "id": "LdFN6FnnGYv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Загрузка датасета\n",
        "x_data, y_data = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "x = (x_data/255.0).astype('float32').to_numpy()\n",
        "y = to_categorical(y_data)\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "IA4qY4VWFuVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Реализация слоев нейронной сети\n",
        "В этом пункте необходимо реализовать forward pass и backward pass для используемых слоев.\n",
        "\n",
        "1. **Линейный слой**\n",
        "$$ f(x, W, b) = xW + b $$\n"
      ],
      "metadata": {
        "id": "AKzxBmB4JGHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "\n",
        "\n",
        "# Backward pass"
      ],
      "metadata": {
        "id": "IRiwJ6aHMNHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **ReLU**\n",
        "\n",
        "$$ ReLU(x) = max(x, 0)$$\n",
        "В качестве функции активации будем использовать ReLU; напишите функцию, реализующую его работу. Аргументами являются входные данные и флаг `get_grad` (`True`, если нужно найти градиент)"
      ],
      "metadata": {
        "id": "oOjcCXKGMTcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x, get_grad=False):\n",
        "    # YOUR CODE HERE\n",
        "    pass"
      ],
      "metadata": {
        "id": "wALEckf0VCZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Softmax + Cross-entropy loss**\n",
        "\n",
        "$$s_i(x) = \\frac{e^{x_i}}{\\sum\\limits_{j}^K e^{x_j}} $$\n",
        "$$CE(y, \\hat{y}) = - \\frac{1}{N}\\sum\\limits_i^N \\sum\\limits_j^K y_j \\ln\\hat{y_j}$$\n",
        "где $K-$количество классов, $N-$ количество объектов.\n",
        "\n",
        "Если мы используем Softmax вместе с функцией потерь в виде кросс-энтропии, то удобно объединить их вместе в один слой из-за удобства получаемых выражений. Напишите выражения для функции потерь и для градиента (можно без полного вывода) и реализуйте функцию аналогичную прошлому пункту."
      ],
      "metadata": {
        "id": "jNfpId2GNAi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_ce(y_true, x, get_grad=False):\n",
        "    # YOUR CODE HERE\n",
        "    pass"
      ],
      "metadata": {
        "id": "kEmJmdVJVCxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Обучение\n",
        "До начала обучения необходимо сделать еще несколько шагов:\n",
        "\n",
        "- **Инициализация весов**. Начальные значения матриц весов могут сильно влиять на ход обучения. Инициализируйте матрицы $W$ и $b$ случайными числами из нормального распределения.\n",
        "- Выбор **темпа обучения (learning rate)**. Гиперпараметр, отвечающий за размер шага в алгоритме градиентного спуска.\n",
        "- Выбор **количества нейронов в скрытом слое**\n",
        "- **Размер батча**. В глубоком обучении через нейронную сеть редко пропускают сразу весь датасет. Вместо этого входные данные делят на части, которые называются **батчи (batch)**, и пропускают по очереди через сеть, обновляя веса после каждой итерации. Когда все батчи из датасета были использованы для forward и backward проходов, заканчивается **эпоха обучения**.\n",
        "\n",
        "    Такой подход позволяет избежать проблем с памятью (датасет может не помещаться в память целиком), а также улучшить сходимость (обновляем веса после каждого батча, а не только один раз после прохода всего датасета).\n",
        "\n",
        "    Выберите размер батча и разбейте датасет на части."
      ],
      "metadata": {
        "id": "74AJyGhWPhbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCH =\n",
        "BATCH_SIZE =\n",
        "\n",
        "INPUT_SIZE = 784 # размер картинки\n",
        "HIDDEN_SIZE =\n",
        "OUTPUT_SIZE = 10 # 10 классов\n",
        "LR =\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "T16OvlFQM-Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте процесс обучения сети с заданными параметрами. В качестве метрики используйте **Accuracy**, выводите её значение для каждой эпохи; после окончания обучения нарисуйте график зависимости **тренировочного лосса** от эпохи. Наконец, сделайте предсказание обученной моделью на валидационных данных и отобразите результат."
      ],
      "metadata": {
        "id": "Lg6ziUspV-Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "IumLMGGDWM8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}